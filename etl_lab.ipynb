{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c47c52-b04e-4cdf-8667-0906528d92a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full Extraction:\n",
      "Number of rows: 100\n",
      "Number of columns: 6\n",
      "Sample data:\n",
      "  transaction_id customer_id     product    price  quantity  \\\n",
      "0          T0001       C6428  Headphones  1212.46         4   \n",
      "1          T0002       C5981     Printer  1131.98         5   \n",
      "2          T0003       C3602       Phone   541.59         4   \n",
      "3          T0004       C7884  Headphones   538.00         2   \n",
      "4          T0005       C4351  Headphones  1173.99         3   \n",
      "\n",
      "     transaction_date  \n",
      "0 2025-05-28 14:15:16  \n",
      "1 2025-06-06 12:04:16  \n",
      "2 2025-05-28 19:27:16  \n",
      "3 2025-05-28 12:02:16  \n",
      "4 2025-06-04 18:24:16  \n",
      "\n",
      " Extracted 100 rows fully.\n",
      "\n",
      " Last extraction time: 2025-06-13 10:52:56\n",
      "\n",
      " Incremental Extraction:\n",
      "Found 0 new or updated records.\n",
      "Empty DataFrame\n",
      "Columns: [transaction_id, customer_id, product, price, quantity, transaction_date]\n",
      "Index: []\n",
      "\n",
      " Updated last extraction timestamp to: 2025-06-13 10:53:25\n",
      "\n",
      " Transformed full dataset saved to transformed_full.csv with 100 rows.\n",
      "\n",
      " Transformed incremental dataset saved to transformed_incremental.csv with 0 rows.\n"
     ]
    }
   ],
   "source": [
    "#  Required Libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#  File Paths\n",
    "DATA_PATH = 'custom_data.csv'\n",
    "TIMESTAMP_FILE = 'last_extraction.txt'\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Section 1: Full Extraction\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Load the entire dataset\n",
    "df_full = pd.read_csv(DATA_PATH, parse_dates=['transaction_date'])\n",
    "\n",
    "# Display basic stats\n",
    "print(\" Full Extraction:\")\n",
    "print(f\"Number of rows: {df_full.shape[0]}\")\n",
    "print(f\"Number of columns: {df_full.shape[1]}\")\n",
    "print(\"Sample data:\")\n",
    "print(df_full.head())\n",
    "\n",
    "# Print extraction message\n",
    "print(f\"\\n Extracted {df_full.shape[0]} rows fully.\\n\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Section 2: Incremental Extraction\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Step 1: Read the last extraction timestamp\n",
    "try:\n",
    "    with open(TIMESTAMP_FILE, 'r') as f:\n",
    "        last_extraction_str = f.read().strip()\n",
    "        last_extraction_time = datetime.strptime(last_extraction_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\" Last extraction time: {last_extraction_str}\")\n",
    "except FileNotFoundError:\n",
    "    print(\" No previous extraction found. Assuming first run.\")\n",
    "    last_extraction_time = datetime.min  # Extract all records\n",
    "\n",
    "# Step 2: Perform incremental extraction\n",
    "df_full['transaction_date'] = pd.to_datetime(df_full['transaction_date'])\n",
    "df_incremental = df_full[df_full['transaction_date'] > last_extraction_time]\n",
    "\n",
    "# Step 3: Display incremental results\n",
    "print(f\"\\n Incremental Extraction:\")\n",
    "print(f\"Found {df_incremental.shape[0]} new or updated records.\")\n",
    "print(df_incremental.head())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Section 3: Save New Timestamp\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Save current timestamp (assuming this is when the ETL ran)\n",
    "current_timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with open(TIMESTAMP_FILE, 'w') as f:\n",
    "    f.write(current_timestamp)\n",
    "\n",
    "print(f\"\\n Updated last extraction timestamp to: {current_timestamp}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Section 4: Transform Full Data\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# 1. Remove duplicates\n",
    "df_full_cleaned = df_full.drop_duplicates()\n",
    "\n",
    "# 2. Enrich with total_price column\n",
    "df_full_cleaned['total_price'] = df_full_cleaned['price'] * df_full_cleaned['quantity']\n",
    "\n",
    "# 3. Format date to YYYY-MM-DD\n",
    "df_full_cleaned['transaction_date'] = pd.to_datetime(df_full_cleaned['transaction_date'])\n",
    "df_full_cleaned['transaction_date'] = df_full_cleaned['transaction_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Save to CSV\n",
    "df_full_cleaned.to_csv('transformed_full.csv', index=False)\n",
    "print(f\"\\n Transformed full dataset saved to transformed_full.csv with {df_full_cleaned.shape[0]} rows.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#  Section 5: Transform Incremental Data\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# 1. Remove duplicates\n",
    "df_incremental_cleaned = df_incremental.drop_duplicates()\n",
    "\n",
    "# 2. Enrich with total_price column\n",
    "df_incremental_cleaned['total_price'] = df_incremental_cleaned['price'] * df_incremental_cleaned['quantity']\n",
    "\n",
    "# 3. Format date to YYYY-MM-DD\n",
    "df_incremental_cleaned['transaction_date'] = pd.to_datetime(df_incremental_cleaned['transaction_date'])\n",
    "df_incremental_cleaned['transaction_date'] = df_incremental_cleaned['transaction_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Save to CSV\n",
    "df_incremental_cleaned.to_csv('transformed_incremental.csv', index=False)\n",
    "print(f\"\\n Transformed incremental dataset saved to transformed_incremental.csv with {df_incremental_cleaned.shape[0]} rows.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ecd5f-b51f-4b6c-85a9-1c3828d8ae56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40dd369-01c8-47c2-9c5c-6122982649b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
